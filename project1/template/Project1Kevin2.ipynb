{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_FOLDER = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from split_data import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, x_train, id_train = load_csv_data(DATA_FOLDER + 'train.csv')\n",
    "y_test, x_test, id_test = load_csv_data(DATA_FOLDER + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train.filter(lambda v: v==v, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100000, 100001, 100002, ..., 349997, 349998, 349999])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_prediction(w_train, x, y):\n",
    "    y_pred = predict_labels(w_train, x)\n",
    "    return (y_pred == y).sum()/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ls, loss_ls = least_squares(y_train, x_train)\n",
    "np.shape(w_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74432799999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction(w_ls, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.asarray([1]*30)[:,None].reshape(30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.asarray([1]*30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w = np.asarray([1]*30)\n",
    "max_iters = 100\n",
    "gamma = 1.0e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_sgd, loss_sgd = least_squares_SGD(y_train, x_train, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63684799999999997"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction(w_sgd, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    e = y - tx @ w\n",
    "    return np.mean(e**2)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "\n",
    "    first_term = tx.T@tx\n",
    "    #sum ici les x*w\n",
    "    left = first_term + lambda_ *np.identity(tx.shape[1])\n",
    "    right = tx.T @ y\n",
    "    w = np.linalg.solve(left, right)\n",
    "    loss = compute_loss(y, tx, w)\n",
    "    return w, loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from build_polynomial import build_poly\n",
    "\n",
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    # split data\n",
    "    x_tr, y_tr, x_te, y_te = split_data(x, y, ratio, seed)\n",
    "    \n",
    "    tr_poly = build_poly(x_tr, degree)\n",
    "    te_poly = build_poly(x_te, degree)\n",
    "    \n",
    "    loss = 1000\n",
    "    w = 0\n",
    "    \n",
    "    for lambda_ in lambdas:\n",
    "        # ridge regression\n",
    "        weight, l = ridge_regression(y_tr, tr_poly, lambda_)\n",
    "        #weight = stack_w(weight, degree)\n",
    "        mse_test = compute_loss(y_te, te_poly, weight)\n",
    "        \n",
    "        if(mse_test < loss):\n",
    "            loss = mse_test\n",
    "            w = weight\n",
    "        \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79597200000000001"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 88\n",
    "degree = 6\n",
    "split_ratio = 0.6\n",
    "\n",
    "\n",
    "w_r, loss_ridge = ridge_regression_demo(x_train, y_train, degree, split_ratio, seed)\n",
    "\n",
    "compare_prediction(w_r, build_poly(x_train, degree), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80079999999999996"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction(w_r, build_poly(x_train, 6), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendu Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w_r, build_poly(x_test, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(id_test, y_pred, \"ridge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge pour seeds et split_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "<class 'numpy.ndarray'>\n",
      "0.7979\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-d60c39367b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msplit_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_ratio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mw_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_ridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge_regression_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_r\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-d2bf97e5beea>\u001b[0m in \u001b[0;36mridge_regression_demo\u001b[0;34m(x, y, degree, ratio, seed)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# ridge regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m#weight = stack_w(weight, degree)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-9779a3f48a58>\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(y, tx, lambda_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#sum ici les x*w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#seed = 95\n",
    "seeds = np.arange(88,89,1)\n",
    "degree = 6\n",
    "split_ratio = np.arange(0.5,1,0.01)\n",
    "best_compare_pred = 0\n",
    "\n",
    "best_seed = 0\n",
    "best_split = 0\n",
    "\n",
    "for seed_ in seeds:\n",
    "    print(seed_)\n",
    "    for split_ in split_ratio:\n",
    "        w_r, loss_ridge = ridge_regression_demo(x_train, y_train, degree, split_, seed_)\n",
    "        \n",
    "        if(type(w_r) is not int):\n",
    "            comp_pred = compare_prediction(w_r.reshape(len(w_r), 1), build_poly(x_train, degree), y_train.reshape(len(y_train), 1))\n",
    "    \n",
    "            print(comp_pred)\n",
    "            if(comp_pred > best_compare_pred):\n",
    "                best_compare_pred = comp_pred\n",
    "                best_seed = seed_\n",
    "                best_split = split_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80079999999999996"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#88\n",
    "best_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from build_k_indices import build_k_indices\n",
    "from implementations import ridge_regression\n",
    "from build_polynomial import build_poly\n",
    "\n",
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "\n",
    "    # get k'th subgroup in test, others in train\n",
    "    train_indices = [x for j, x in enumerate(k_indices) if j != k]\n",
    "    train_indices = [idx for part in train_indices for idx in part]\n",
    "    test_indices = k_indices[k]\n",
    "    \n",
    "    x_tr = x[train_indices]\n",
    "    y_tr = y[train_indices]\n",
    "    \n",
    "    x_te = x[test_indices]\n",
    "    y_te = y[test_indices]\n",
    "\n",
    "    # form data with polynomial degree\n",
    "    #train_poly = build_poly(x_tr, degree)\n",
    "    #test_poly = build_poly(x_te, degree)\n",
    "\n",
    "    # ridge regression\n",
    "    \n",
    "    weights_train, loss_tr = ridge_regression(y_tr, x_tr, lambda_)\n",
    "\n",
    "    # calculate the loss for train and test data\n",
    "    loss_te = compute_loss(y_te, x_te, weights_train)\n",
    "\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_demo():\n",
    "    seed = 55\n",
    "    degree = 2\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    \n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "    \n",
    "    min_mean_loss = 1000\n",
    "    best_lambdas = np.zeros(k_fold)\n",
    "    # cross validation\n",
    "    for i_test in range(k_fold):\n",
    "        min_loss = 1000\n",
    "        for lambda_ in lambdas:\n",
    "            loss_tr, loss_te = cross_validation(y_train, x_train, k_indices, i_test, lambda_, degree)\n",
    "            \n",
    "            if(loss_te < min_loss):\n",
    "                min_loss = loss_te\n",
    "                best_lambdas[i_test] = lambda_\n",
    "    lambda_mean = np.mean(best_lambdas)\n",
    "    return lambda_mean, min_mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl, mml = cross_validation_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25007499999999999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, l = ridge_regression(y_train, x_train, bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74440799999999996"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction(w, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methode for Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle_index separate the index on y if it's a 1 or -1 and then shuffle the indexes. At the end it choose a number of elems (same in both list) and take them. With this we will have the same mount of 1 and -1 and we will have better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_index_resize(y,x, max_elem_percent):\n",
    "    y_pos = []\n",
    "    y_neg = []\n",
    "    \n",
    "    max_elem = int(((max_elem_percent * len(y) ) / 100) / 2.0)\n",
    "\n",
    "    for idx_y, val in enumerate(y):\n",
    "\n",
    "        if(val == 1):\n",
    "            y_pos.append(idx_y)\n",
    "        else:\n",
    "            y_neg.append(idx_y)\n",
    "        \n",
    "    data_size_pos = len(y_pos)  \n",
    "    shuffle_indices_pos = np.random.permutation(np.arange(data_size_pos)) \n",
    "    data_size_neg = len(y_neg)  \n",
    "    shuffle_indices_neg = np.random.permutation(np.arange(data_size_neg)) \n",
    "    new_y = []\n",
    "    new_x = []\n",
    "    for i in range(max_elem):\n",
    "        new_y.append(y[y_pos[shuffle_indices_pos[i]]])\n",
    "        new_y.append(y[y_neg[shuffle_indices_neg[i]]])\n",
    "        new_x.append(x[y_pos[shuffle_indices_pos[i]]])\n",
    "        new_x.append(x[y_neg[shuffle_indices_neg[i]]])\n",
    "    \n",
    "    return np.array(new_y), np.array(new_x)\n",
    "\n",
    "\n",
    "def shuffle_index_resize2(y,x, max_elem_percent):\n",
    "    y_pos = []\n",
    "    y_neg = []\n",
    "    \n",
    "    max_elem = int(max_elem_percent / 2)\n",
    "\n",
    "    for idx_y, val in enumerate(y):\n",
    "\n",
    "        if(val == 1):\n",
    "            y_pos.append(idx_y)\n",
    "        else:\n",
    "            y_neg.append(idx_y)\n",
    "\n",
    "        \n",
    "    data_size_pos = len(y_pos)  \n",
    "    shuffle_indices_pos = np.random.permutation(np.arange(data_size_pos)) \n",
    "    data_size_neg = len(y_neg)  \n",
    "    shuffle_indices_neg = np.random.permutation(np.arange(data_size_neg)) \n",
    "    new_y = []\n",
    "    new_x = []\n",
    "    for i in range(max_elem):\n",
    "        new_y.append(y[y_pos[shuffle_indices_pos[i]]])\n",
    "        new_y.append(y[y_neg[shuffle_indices_neg[i]]])\n",
    "        new_x.append(x[y_pos[shuffle_indices_pos[i]]])\n",
    "        new_x.append(x[y_neg[shuffle_indices_neg[i]]])\n",
    "    \n",
    "    return np.array(new_y), np.array(new_x)\n",
    "\n",
    "\n",
    "new_y, new_x = shuffle_index_resize(y_train, x_train, 0.2)\n",
    "\n",
    "np.shape(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was to predic y when use sigma between 0 and 1 to determine w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_prediction2(w_train, x, y):\n",
    "    y_pred = np.dot(x,w)\n",
    "    y_pred[np.where(y_pred <= 0.5)] = 0\n",
    "    y_pred[np.where(y_pred > 0.5)] = 1\n",
    "    \n",
    "    return (y_pred == y).sum()/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics regression cross \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_gradient2(y, x, w, max_iter, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    #gammas = np.logspace(-12, -9, 10)\n",
    "    gammas = np.arange(1e-12,1e-11,1e-13)\n",
    "    lambdas = [0.9]\n",
    "    #lambdas = np.logspace(-7, 0, 30)\n",
    "    # split data\n",
    "    \n",
    "    x_tr, y_tr, x_te, y_te = split_data(x, y, ratio, seed)\n",
    "    \n",
    "    best_comp = 0   \n",
    "    weight = 0\n",
    "    best_loss = 0\n",
    "    w_init = w\n",
    "    best_gamma = 0\n",
    "    best_lambda = 0\n",
    "    \n",
    "    for gamma_ in gammas: \n",
    "        print(\"gamma\")\n",
    "        print(gamma_)\n",
    "        for lambda_ in lambdas:\n",
    "            w = w_init\n",
    "            print(\"lambda\")\n",
    "            print(lambda_)\n",
    "            for iter_ in range(max_iter):\n",
    "                \n",
    "                if((iter_ % 1000) == 0):\n",
    "                    print(iter_)\n",
    "                #loss, w = learning_by_gradient_descent(y, x, w, gamma_)\n",
    "                loss, w = learning_by_penalized_gradient(y_tr, x_tr, w, gamma_, lambda_)\n",
    "            \n",
    "            print(\"ok\")\n",
    "            comp_pred = compare_prediction2(w, x_tr, y_tr)\n",
    "            print(comp_pred)\n",
    "            if(comp_pred > best_comp):\n",
    "                best_comp = comp_pred\n",
    "                print(\"best_comp\")\n",
    "                print(best_comp)\n",
    "                weight = w\n",
    "                #best_loss = loss\n",
    "                best_gamma = gamma_\n",
    "                best_lambda = lambda_\n",
    "        \n",
    "    return weight, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_prediction2(w_train, x, y):\n",
    "    y_pred = np.dot(x,w)\n",
    "    y_pred[np.where(y_pred <= 0.5)] = 0\n",
    "    y_pred[np.where(y_pred > 0.5)] = 1\n",
    "    \n",
    "    return (y_pred == y).sum()/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 88\n",
    "degree = 6\n",
    "split_ratio = 0.6\n",
    "max_iter = 7000\n",
    "\n",
    "y_train3 = y_train.reshape(len(y_train), 1)\n",
    "tx = np.c_[np.ones((y_train3.shape[0], 1)), x_train]\n",
    "w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "for i in range(len(y_train3)):\n",
    "    if(y_train3[i] < 0):\n",
    "        y_train3[i] = 0\n",
    "\n",
    "\n",
    "w_l, loss_log = logistic_regression_gradient2(y_train3, tx, w, max_iter, degree, split_ratio, seed)\n",
    "\n",
    "\n",
    "compare_prediction2(w_l, tx, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prediction2(w_l, tx, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma\n",
      "1e-12\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.68966\n",
      "best_comp\n",
      "0.68966\n",
      "gamma\n",
      "2.15443469003e-12\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.692066666667\n",
      "best_comp\n",
      "0.692066666667\n",
      "gamma\n",
      "4.64158883361e-12\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.696913333333\n",
      "best_comp\n",
      "0.696913333333\n",
      "gamma\n",
      "1e-11\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.706013333333\n",
      "best_comp\n",
      "0.706013333333\n",
      "gamma\n",
      "2.15443469003e-11\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.724386666667\n",
      "best_comp\n",
      "0.724386666667\n",
      "gamma\n",
      "4.64158883361e-11\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.5455\n",
      "gamma\n",
      "1e-10\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.704206666667\n",
      "gamma\n",
      "2.15443469003e-10\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.513006666667\n",
      "gamma\n",
      "4.64158883361e-10\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.691306666667\n",
      "gamma\n",
      "1e-09\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "ok\n",
      "0.704166666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70423999999999998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 88\n",
    "degree = 5\n",
    "split_ratio = 0.6\n",
    "max_iter = 10000\n",
    "\n",
    "y_train3 = y_train.reshape(len(y_train), 1)\n",
    "tx = np.c_[np.ones((y_train3.shape[0], 1)), x_train]\n",
    "w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "for i in range(len(y_train3)):\n",
    "    if(y_train3[i] < 0):\n",
    "        y_train3[i] = 0\n",
    "\n",
    "\n",
    "w_l, loss_log = logistic_regression_gradient2(y_train3, tx, w, max_iter, degree, split_ratio, seed)\n",
    "\n",
    "\n",
    "compare_prediction2(w_l, tx, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70957999999999999"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction(w_r, tx, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Valid Logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_valid_vizu(values, name, rmse_tr, rmse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(values, rmse_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(values, rmse_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"rmse\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"cross_validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_polynomial import *\n",
    "def cross_validation_logi(y, x, k_indices, k, lambda_, degree, max_iters, gamma):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "\n",
    "    # get k'th subgroup in test, others in train\n",
    "    train_indices = [x for j, x in enumerate(k_indices) if j != k]\n",
    "    train_indices = [idx for part in train_indices for idx in part]\n",
    "    test_indices = k_indices[k]\n",
    "    \n",
    "    x_tr = x[train_indices]\n",
    "    y_tr = y[train_indices]\n",
    "    \n",
    "    x_te = x[test_indices]\n",
    "    y_te = y[test_indices]\n",
    "    \n",
    "    y_tr = y_tr.reshape(len(y_tr), 1)\n",
    "    #x_tr = np.c_[np.ones((y_tr.shape[0], 1)), x_tr]\n",
    "    #initial_w = np.zeros((x_tr.shape[1], 1))\n",
    "    \n",
    "    # form data with polynomial degree\n",
    "    #train_poly = build_poly(x_tr, degree)\n",
    "    #test_poly = build_poly(x_te, degree)\n",
    "    \n",
    "    #initial_w = np.transpose(build_poly(np.transpose(initial_w), degree))\n",
    "    \n",
    "    x_te = np.c_[np.ones((y_te.shape[0], 1)), x_te]\n",
    "    x_tr = np.c_[np.ones((y_tr.shape[0], 1)), x_tr]\n",
    "    initial_w = np.zeros((x_tr.shape[1], 1))\n",
    "\n",
    "    # ridge regression\n",
    "    weights_train, loss_tr = reg_logistic_regression(y_tr, x_tr, lambda_, initial_w, max_iters, gamma)\n",
    "    \n",
    "    # calculate the loss for train and test data\n",
    "    loss_te = calculate_loss(y_te, x_te, weights_train)\n",
    "\n",
    "    return loss_tr, loss_te, weights_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from build_k_indices import *\n",
    "\n",
    "def cross_validation_logi_demo(lambdas, degrees, gammas, k_fold, max_iters):\n",
    "    \n",
    "    seed = 1\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y_train[:4000], k_fold, seed)\n",
    "    \n",
    "    best_l = 0 \n",
    "    best_deg = 0\n",
    "    best_g = 0\n",
    "    min_loss = 10000\n",
    "    best_pred = 0\n",
    "     # define list to store the variable\n",
    "    rmse_tr = np.empty((len(lambdas), len(degrees), len(gammas)))\n",
    "    rmse_te = np.empty((len(lambdas), len(degrees), len(gammas)))\n",
    "    \n",
    "    for ind_l, l in enumerate(lambdas):\n",
    "        print(\"lambda_\")\n",
    "        print(ind_l)\n",
    "        for ind_deg, deg in enumerate(degrees):\n",
    "            for ind_g, g in enumerate(gammas):\n",
    "                print(\"gamma\")\n",
    "                print(g)\n",
    "                losses_tr_tmp = []\n",
    "                losses_te_tmp = []\n",
    "                for k_test in range(k_fold):\n",
    "                    loss_tr, loss_te, we = cross_validation_logi(y_train[:100000],  \\\n",
    "                                                x_train[:100000], k_indices, k_test, l, deg, max_iters, g)\n",
    "                    losses_tr_tmp.append(loss_tr)\n",
    "                    losses_te_tmp.append(loss_te)\n",
    "                mean_tr = np.mean(losses_tr_tmp)\n",
    "                mean_te = np.mean(losses_te_tmp)\n",
    "                rmse_t = np.sqrt(2*mean_te)\n",
    "                rmse_tr[ind_l][ind_deg] = np.sqrt(2*mean_tr)\n",
    "                rmse_te[ind_l][ind_deg] = rmse_t\n",
    "                \n",
    "                \n",
    "                y_train2 = y_train.reshape(len(y_train), 1)\n",
    "                x_train2 = np.c_[np.ones((y_train2.shape[0], 1)), x_train]\n",
    "                \n",
    "                pred = compare_prediction(we, x_train2, y_train2)\n",
    "                \n",
    "                print(pred)\n",
    "                if(pred > best_pred):\n",
    "                    best_pred = pred\n",
    "                #print(rmse_t)\n",
    "                #if(rmse_t < min_loss):\n",
    "                    min_loss = rmse_t\n",
    "                    best_l = l\n",
    "                    best_deg = deg\n",
    "                    best_g = g\n",
    "     \n",
    "    #cross_valid_vizu(lambdas, 'gamma', rmse_tr[0, 0, :], rmse_te[0, 0, :])\n",
    "    #cross_valid_vizu(lambdas, 'gamma', rmse_tr[len(lambdas)-1, 0, :], rmse_te[len(lambdas)-1, 0, :])\n",
    "    return best_l, best_deg, best_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(2, 3)\n",
    "k_fold = 4\n",
    "lambdas = [0.9]\n",
    "gammas_ridge = np.logspace(-15, -8, 50)\n",
    "max_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_\n",
      "0\n",
      "gamma\n",
      "1e-15\n",
      "0.63892\n",
      "gamma\n",
      "1.38949549437e-15\n",
      "0.638928\n",
      "gamma\n",
      "1.93069772888e-15\n",
      "0.638924\n",
      "gamma\n",
      "2.68269579528e-15\n",
      "0.638936\n",
      "gamma\n",
      "3.72759372031e-15\n",
      "0.638948\n",
      "gamma\n",
      "5.17947467923e-15\n",
      "0.638952\n",
      "gamma\n",
      "7.19685673001e-15\n",
      "0.638988\n",
      "gamma\n",
      "1e-14\n",
      "0.63904\n",
      "gamma\n",
      "1.38949549437e-14\n",
      "0.63908\n",
      "gamma\n",
      "1.93069772888e-14\n",
      "0.63914\n",
      "gamma\n",
      "2.68269579528e-14\n",
      "0.63922\n",
      "gamma\n",
      "3.72759372031e-14\n",
      "0.639312\n",
      "gamma\n",
      "5.17947467923e-14\n",
      "0.639424\n",
      "gamma\n",
      "7.19685673001e-14\n",
      "0.639572\n",
      "gamma\n",
      "1e-13\n",
      "0.639664\n",
      "gamma\n",
      "1.38949549437e-13\n",
      "0.639896\n",
      "gamma\n",
      "1.93069772888e-13\n",
      "0.640096\n",
      "gamma\n",
      "2.68269579528e-13\n",
      "0.640276\n",
      "gamma\n",
      "3.72759372031e-13\n",
      "0.640304\n",
      "gamma\n",
      "5.17947467923e-13\n",
      "0.640424\n",
      "gamma\n",
      "7.19685673001e-13\n",
      "0.640456\n",
      "gamma\n",
      "1e-12\n",
      "0.640732\n",
      "gamma\n",
      "1.38949549437e-12\n",
      "0.64142\n",
      "gamma\n",
      "1.93069772888e-12\n",
      "0.643156\n",
      "gamma\n",
      "2.68269579528e-12\n",
      "0.646584\n",
      "gamma\n",
      "3.72759372031e-12\n",
      "0.652112\n",
      "gamma\n",
      "5.17947467923e-12\n",
      "0.660636\n",
      "gamma\n",
      "7.19685673001e-12\n",
      "0.66906\n",
      "gamma\n",
      "1e-11\n",
      "0.676692\n",
      "gamma\n",
      "1.38949549437e-11\n",
      "0.682388\n",
      "gamma\n",
      "1.93069772888e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkappel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686872\n",
      "gamma\n",
      "2.68269579528e-11\n",
      "0.68916\n",
      "gamma\n",
      "3.72759372031e-11\n",
      "0.691572\n",
      "gamma\n",
      "5.17947467923e-11\n",
      "0.693436\n",
      "gamma\n",
      "7.19685673001e-11\n",
      "0.694984\n",
      "gamma\n",
      "1e-10\n",
      "0.69644\n",
      "gamma\n",
      "1.38949549437e-10\n",
      "0.697364\n",
      "gamma\n",
      "1.93069772888e-10\n",
      "0.697932\n",
      "gamma\n",
      "2.68269579528e-10\n",
      "0.698404\n",
      "gamma\n",
      "3.72759372031e-10\n",
      "0.59024\n",
      "gamma\n",
      "5.17947467923e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinkappel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699064\n",
      "gamma\n",
      "7.19685673001e-10\n",
      "0.529244\n",
      "gamma\n",
      "1e-09\n",
      "0.694776\n",
      "gamma\n",
      "1.38949549437e-09\n",
      "0.504304\n",
      "gamma\n",
      "1.93069772888e-09\n",
      "0.498848\n",
      "gamma\n",
      "2.68269579528e-09\n",
      "0.497084\n",
      "gamma\n",
      "3.72759372031e-09\n",
      "0.69746\n",
      "gamma\n",
      "5.17947467923e-09\n",
      "0.687728\n",
      "gamma\n",
      "7.19685673001e-09\n",
      "0.494796\n",
      "gamma\n",
      "1e-08\n",
      "0.698648\n"
     ]
    }
   ],
   "source": [
    "bl, bd, bg = cross_validation_logi_demo(lambdas, degrees, gammas_ridge, k_fold, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(bl)\n",
    "print(bd)\n",
    "print(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697932"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = 1\n",
    "max_iter = 1000\n",
    "gamma = 4.2e-10\n",
    "lambda_ = 0.9\n",
    "\n",
    "y_train2 = y_train.reshape(len(y_train), 1)\n",
    "train_poly = build_poly(x_train, degree)\n",
    "\n",
    "#train_poly = np.c_[np.ones((y_train2.shape[0], 1)), train_poly]\n",
    "initial_w = np.zeros((train_poly.shape[1], 1))\n",
    "\n",
    "w_l, loss_log = reg_logistic_regression(y_train2, train_poly, lambda_, initial_w, max_iters, gamma)\n",
    "\n",
    "compare_prediction(w_l, train_poly, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 61)\n",
      "(61, 1)\n",
      "(250000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14075599999999999"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = 1\n",
    "max_iter = 1000\n",
    "gamma = 4.2e-8\n",
    "lambda_ = 0.9\n",
    "\n",
    "print(np.shape(train_poly))\n",
    "print(np.shape(w_l))\n",
    "print(np.shape(y_train2))\n",
    "compare_prediction(w_l, train_poly, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
